{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b7dc1d",
   "metadata": {},
   "source": [
    "**Import Libraries and Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f798777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df_cleaned = pd.read_csv('../data/cleaned_diabetes_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c9a32",
   "metadata": {},
   "source": [
    "**Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2659e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert DataFrame to PyTorch tensors\n",
    "X = torch.tensor(df_cleaned.drop('Diabetes_012', axis=1).values, dtype=torch.float32)\n",
    "y = torch.tensor(df_cleaned['Diabetes_012'].values, dtype=torch.long)\n",
    "\n",
    "# Split data into training and remaining dataset with 70% and 30% respectively\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split remaining dataset into validation and testing sets equally (50% each of the remaining data)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_remaining, y_remaining, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b3248-1030-44be-be31-a249acd85637",
   "metadata": {},
   "source": [
    "**Minority Class Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3598ec9-553c-4942-8b91-b5972285ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the cost of misclassifying the minority class during training\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train.numpy()), y=y_train.numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42412c92",
   "metadata": {},
   "source": [
    "**NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd36a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.fc4 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(params):\n",
    "    model = NeuralNet(X_train.shape[1], params['hidden_size'], 3).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    for epoch in range(params['num_epochs']):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521f266",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569344d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|████████████▌                                                       | 5/27 [04:09<19:24, 52.91s/it, LR: 0.001, Hidden: 100, Epochs: 10, Acc: 0.6594, Time: 61.33s]"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'hidden_size': [50, 100, 150],\n",
    "    'num_epochs': [5, 10, 15]\n",
    "}\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Calculate the total number of iterations\n",
    "total_iterations = len(hyperparams['learning_rate']) * len(hyperparams['hidden_size']) * len(hyperparams['num_epochs'])\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Hyperparameter Tuning\") as pbar:\n",
    "    for lr in hyperparams['learning_rate']:\n",
    "        for hidden_size in hyperparams['hidden_size']:\n",
    "            for num_epochs in hyperparams['num_epochs']:\n",
    "                params = {'learning_rate': lr, 'hidden_size': hidden_size, 'num_epochs': num_epochs}\n",
    "                \n",
    "                start_time = time.time()  # Start time for the current set of parameters\n",
    "                model = train_model(params)\n",
    "                \n",
    "                # Evaluate the model\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    for inputs, labels in val_loader:\n",
    "                        outputs = model(inputs)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                accuracy = correct / total\n",
    "\n",
    "                elapsed_time = time.time() - start_time  # Calculate elapsed time\n",
    "\n",
    "                # Update best accuracy and parameters if current model is better\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = params\n",
    "\n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix_str(f\"LR: {lr}, Hidden: {hidden_size}, Epochs: {num_epochs}, Acc: {accuracy:.4f}, Time: {elapsed_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521aa38",
   "metadata": {},
   "source": [
    "**Train Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train_model(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0f928",
   "metadata": {},
   "source": [
    "**Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ff99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.tolist())\n",
    "            y_pred.extend(predicted.tolist())\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# After training your best_model and creating the test_loader, call this function\n",
    "accuracy, precision, recall, f1 = evaluate_model(best_model, test_loader)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5596bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
